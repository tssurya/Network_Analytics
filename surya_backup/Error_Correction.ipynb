{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25643\n",
      "10990\n",
      "hey hey\n",
      "2.623400926589966\n",
      "this is the time!!\n",
      "[ 23.98333333  20.53333333  21.86666667 ...,  23.96666667  23.99166667\n",
      "  23.33333333]\n",
      "<<======================================================================================>>\n",
      "0        12.0\n",
      "2        24.0\n",
      "19       24.0\n",
      "20       24.0\n",
      "24       24.0\n",
      "27       24.0\n",
      "28       24.0\n",
      "31       24.0\n",
      "32       24.0\n",
      "34       24.0\n",
      "37       23.0\n",
      "40       24.0\n",
      "44       24.0\n",
      "50       24.0\n",
      "53       24.0\n",
      "54       24.0\n",
      "69       24.0\n",
      "79       24.0\n",
      "80       24.0\n",
      "90       24.0\n",
      "91       24.0\n",
      "92       24.0\n",
      "97       24.0\n",
      "98       24.0\n",
      "101      24.0\n",
      "111      24.0\n",
      "118      24.0\n",
      "120      24.0\n",
      "124      24.0\n",
      "126      24.0\n",
      "         ... \n",
      "10861    24.0\n",
      "10867    24.0\n",
      "10868    24.0\n",
      "10870    24.0\n",
      "10872    24.0\n",
      "10879    24.0\n",
      "10880    24.0\n",
      "10884    24.0\n",
      "10896    24.0\n",
      "10897    24.0\n",
      "10899    24.0\n",
      "10900    24.0\n",
      "10903    24.0\n",
      "10904    24.0\n",
      "10907    24.0\n",
      "10908    24.0\n",
      "10910    24.0\n",
      "10932    24.0\n",
      "10938    24.0\n",
      "10948    24.0\n",
      "10955    24.0\n",
      "10961     7.0\n",
      "10966    24.0\n",
      "10972    24.0\n",
      "10974    24.0\n",
      "10975    24.0\n",
      "10983    24.0\n",
      "10985    24.0\n",
      "10986    24.0\n",
      "10987    24.0\n",
      "Name: 38, dtype: float64\n",
      "2.28487290763\n",
      "22.204587724736516\n",
      "0.102900938128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "A = genfromtxt('X_flow.csv', delimiter = ',')[1:]\n",
    "B = genfromtxt('Y.csv' , delimiter = ',')[1:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "#print(data_set)\n",
    "#random.shuffle(data_set)\n",
    "\n",
    "df = pandas.DataFrame(data_set)\n",
    "training_set = df.sample(frac=0.7)\n",
    "train_size = len(training_set)\n",
    "test_set = df.loc[~df.index.isin(training_set.index)]\n",
    "test_size = len(test_set)\n",
    "print(len(training_set))\n",
    "print (len(test_set))\n",
    "\n",
    "#print(training_set)\n",
    "train = training_set.ix[:25643, :24]\n",
    "target = training_set.ix[:25643, 38]\n",
    "#print (len(train))\n",
    "#print (target)\n",
    "\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 24)\n",
    "rf = rf.fit(train, target)\n",
    "end = time.time()\n",
    "print(\"hey hey\")\n",
    "print(end - start)\n",
    "print(\"this is the time!!\")\n",
    "y_pred = rf.predict(test_set.ix[:10990, :24])\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = test_set.ix[:10990, 38]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25643\n",
      "10990\n",
      "hey hey\n",
      "26.14305591583252\n",
      "this is the time!!\n",
      "[ 22.          23.43333333  22.54166667 ...,  23.875       17.65\n",
      "  19.16666667]\n",
      "<<======================================================================================>>\n",
      "2        24.0\n",
      "3        24.0\n",
      "9        24.0\n",
      "10       24.0\n",
      "13       24.0\n",
      "15       24.0\n",
      "19       24.0\n",
      "26       24.0\n",
      "29       24.0\n",
      "34       24.0\n",
      "35       24.0\n",
      "40       24.0\n",
      "41       24.0\n",
      "42       24.0\n",
      "43       24.0\n",
      "44       24.0\n",
      "46       24.0\n",
      "49       24.0\n",
      "52       24.0\n",
      "55       24.0\n",
      "58       24.0\n",
      "67       24.0\n",
      "68       24.0\n",
      "72       24.0\n",
      "76       13.0\n",
      "79       24.0\n",
      "82       24.0\n",
      "83       13.0\n",
      "84       24.0\n",
      "88       24.0\n",
      "         ... \n",
      "10913    24.0\n",
      "10914    24.0\n",
      "10916    24.0\n",
      "10917    24.0\n",
      "10922    24.0\n",
      "10923    20.0\n",
      "10924    24.0\n",
      "10926    24.0\n",
      "10929    24.0\n",
      "10935    24.0\n",
      "10936    14.0\n",
      "10939    24.0\n",
      "10943    24.0\n",
      "10946    24.0\n",
      "10948    24.0\n",
      "10949    24.0\n",
      "10951    13.0\n",
      "10956    13.0\n",
      "10958    24.0\n",
      "10959    24.0\n",
      "10961    24.0\n",
      "10966    10.0\n",
      "10967    24.0\n",
      "10977    24.0\n",
      "10980    13.0\n",
      "10981    24.0\n",
      "10985    24.0\n",
      "10987    23.0\n",
      "10988     5.0\n",
      "10989    24.0\n",
      "Name: 38, dtype: float64\n",
      "2.3524095181\n",
      "22.083983203359328\n",
      "0.106521069883\n"
     ]
    }
   ],
   "source": [
    "#VoD_flashcrowd/X_flow.csv -> working code copied frm Random Forest.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "A = genfromtxt('X_flow.csv', delimiter = ',', dtype = 'double')[1:]\n",
    "B = genfromtxt('Y.csv' , delimiter = ',', dtype = 'double')[1:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "#print(data_set)\n",
    "random.shuffle(data_set)\n",
    "\n",
    "df = pandas.DataFrame(data_set)\n",
    "training_set = df.sample(frac=0.7)\n",
    "train_size = len(training_set)\n",
    "test_set = df.loc[~df.index.isin(training_set.index)]\n",
    "test_size = len(test_set)\n",
    "print(len(training_set))\n",
    "print (len(test_set))\n",
    "\n",
    "#print(training_set)\n",
    "train = training_set.ix[:25643, :24]\n",
    "target = training_set.ix[:25643, 38]\n",
    "#print (len(train))\n",
    "#print (target)\n",
    "\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 2)\n",
    "rf = rf.fit(train, target)\n",
    "end = time.time()\n",
    "print(\"hey hey\")\n",
    "print(end - start)\n",
    "print(\"this is the time!!\")\n",
    "y_pred = rf.predict(test_set.ix[:10990, :24])\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = test_set.ix[:10990, 38]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "A = genfromtxt('X_flow.csv', delimiter = ',')[0:]\n",
    "B = genfromtxt('Y.csv' , delimiter = ',')[0:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "#print(data_set)\n",
    "random.shuffle(data_set)\n",
    "training_set, test_set, = train_test_split(data_set, test_size=0.3)\n",
    "train = training_set[:, 1:25]\n",
    "target = training_set[:, 38]\n",
    "print (train)\n",
    "print (target)\n",
    "print (test_set)\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 24)\n",
    "rf = rf.fit(train, target)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "y_pred = rf.predict(test_set[:, 1:25])\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = test_set[:, 38]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28962\n",
      "10375\n",
      "28962\n",
      "23\n",
      "[[  1.47962603e+09   2.23000000e+00   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47962604e+09   3.48000000e+00   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47962604e+09   5.40000000e+00   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " ..., \n",
      " [  1.47965756e+09   8.00000000e-02   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47965756e+09   1.30000000e-01   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47965757e+09   1.70000000e-01   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]]\n",
      "[ 73.8254  56.2413  56.8517 ...,  53.8244  53.9819  54.2854]\n",
      "[[  1.47965757e+09   2.50000000e-01   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47965757e+09   2.50000000e-01   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47965757e+09   2.50000000e-01   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " ..., \n",
      " [  1.47967094e+09   4.00000000e-02   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47967096e+09   4.00000000e-02   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]\n",
      " [  1.47967097e+09   4.00000000e-02   0.00000000e+00 ...,   1.24184000e+05\n",
      "    3.12000000e+02   2.50000000e-01]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6fa432ff0ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#KV_periodic/X_cluster.csv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "A = genfromtxt('X_cluster.csv', delimiter = ',', dtype = 'float64')[1:]\n",
    "B = genfromtxt('Y1.csv' , delimiter = ',', dtype = 'float64')[1:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "print(len(A))\n",
    "print(len(A[0]))\n",
    "print(len(B))\n",
    "print(len(B[0]))\n",
    "#random.shuffle(data_set)\n",
    "training_set = data_set[:20273, :10375]\n",
    "target_set =  data_set [:20273, 10376]\n",
    "test_set = data_set [20273:28963, :10375]\n",
    "print (training_set)\n",
    "print (target_set)\n",
    "print (test_set)\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 24)\n",
    "rf = rf.fit(training_set, target_set)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "y_pred = rf.predict(test_set)\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = data_set[20273:28963, 10376]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural Networks\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20273\n",
      "8689\n",
      "hey hey\n",
      "119.02191519737244\n",
      "this is the time!!\n",
      "[ 53.75410083  58.42479274  59.04846833 ...,  53.23122896  54.17341972\n",
      "  58.32222542]\n",
      "<<======================================================================================>>\n",
      "1       52.8989\n",
      "3       60.4065\n",
      "8       60.1181\n",
      "10      53.4543\n",
      "15      60.4613\n",
      "25      56.7521\n",
      "30      58.0105\n",
      "31      52.5687\n",
      "32      67.1475\n",
      "33      54.5146\n",
      "38      53.7758\n",
      "41      54.4325\n",
      "43      54.8038\n",
      "51      52.9474\n",
      "58      62.9081\n",
      "61      53.4246\n",
      "68      53.6826\n",
      "71      55.2825\n",
      "73      53.6252\n",
      "77      59.9686\n",
      "84      54.7569\n",
      "86      55.3337\n",
      "91      69.9419\n",
      "93      56.3943\n",
      "94      55.6490\n",
      "96      55.6203\n",
      "100     52.9867\n",
      "106     53.9255\n",
      "108     56.4421\n",
      "114     53.2540\n",
      "         ...   \n",
      "8547    57.6231\n",
      "8554    59.1036\n",
      "8559    56.2411\n",
      "8560    58.6651\n",
      "8564    56.2224\n",
      "8566    56.3075\n",
      "8573    52.0846\n",
      "8574    54.6773\n",
      "8579    58.6891\n",
      "8580    55.1446\n",
      "8582    58.0223\n",
      "8584    53.1800\n",
      "8585    55.7403\n",
      "8604    57.2249\n",
      "8612    55.5103\n",
      "8615    54.0863\n",
      "8616    57.3331\n",
      "8621    53.8535\n",
      "8626    60.4446\n",
      "8632    62.0426\n",
      "8635    60.6862\n",
      "8641    53.5168\n",
      "8642    58.1997\n",
      "8652    57.6686\n",
      "8656    56.3877\n",
      "8669    59.8237\n",
      "8673    56.1461\n",
      "8676    52.9199\n",
      "8684    55.0160\n",
      "8686    57.1511\n",
      "Name: 10376, dtype: float64\n",
      "1.20421421163\n",
      "55.96120646284833\n",
      "0.0215187321315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#data = pandas.read_csv('X_cluster.csv')\n",
    "#data.isnull().any()\n",
    "A = genfromtxt('X_cluster.csv', delimiter = ',', dtype = 'float64')[1:]\n",
    "B = genfromtxt('Y1.csv' , delimiter = ',', dtype = 'float64')[1:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "#print(data_set)\n",
    "random.shuffle(data_set)\n",
    "\n",
    "data = pandas.DataFrame(data_set)\n",
    "df = data.fillna(0)\n",
    "training_set = df.sample(frac=0.7)\n",
    "train_size = len(training_set)\n",
    "test_set = df.loc[~df.index.isin(training_set.index)]\n",
    "test_size = len(test_set)\n",
    "print(len(training_set))\n",
    "print (len(test_set))\n",
    "\n",
    "#print(training_set)\n",
    "train = training_set.ix[:20274, :10374]\n",
    "target = training_set.ix[:20274, 10376]\n",
    "#print (len(train))\n",
    "#print (target)\n",
    "\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 24)\n",
    "rf = rf.fit(train, target)\n",
    "end = time.time()\n",
    "print(\"hey hey\")\n",
    "print(end - start)\n",
    "print(\"this is the time!!\")\n",
    "y_pred = rf.predict(test_set.ix[:8690, :10374])\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = test_set.ix[:8690, 10376]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStamp                                False\n",
       "0_all_..usr                              False\n",
       "0_all_..nice                             False\n",
       "0_all_..sys                              False\n",
       "0_all_..iowait                           False\n",
       "0_all_..steal                            False\n",
       "0_all_..irq                              False\n",
       "0_all_..soft                             False\n",
       "0_all_..guest                            False\n",
       "0_all_..gnice                            False\n",
       "0_all_..idle                             False\n",
       "0_cpu0_.usr                              False\n",
       "0_cpu0_.nice                             False\n",
       "0_cpu0_.sys                              False\n",
       "0_cpu0_.iowait                           False\n",
       "0_cpu0_.steal                            False\n",
       "0_cpu0_.irq                              False\n",
       "0_cpu0_.soft                             False\n",
       "0_cpu0_.guest                            False\n",
       "0_cpu0_.gnice                            False\n",
       "0_cpu0_.idle                             False\n",
       "0_cpu1_.usr                              False\n",
       "0_cpu1_.nice                             False\n",
       "0_cpu1_.sys                              False\n",
       "0_cpu1_.iowait                           False\n",
       "0_cpu1_.steal                            False\n",
       "0_cpu1_.irq                              False\n",
       "0_cpu1_.soft                             False\n",
       "0_cpu1_.guest                            False\n",
       "0_cpu1_.gnice                            False\n",
       "                                         ...  \n",
       "5_temp3_DEVICE                           False\n",
       "5_temp3_degC                             False\n",
       "5_temp3_.temp                            False\n",
       "5_temp4_DEVICE                           False\n",
       "5_temp4_degC                             False\n",
       "5_temp4_.temp                            False\n",
       "5_bus2_idvendor                          False\n",
       "5_bus2_idprod                            False\n",
       "5_bus2_maxpower                          False\n",
       "5_bus2_manufact                           True\n",
       "5_bus2_product                            True\n",
       "5_bus3_idvendor                          False\n",
       "5_bus3_idprod                            False\n",
       "5_bus3_maxpower                          False\n",
       "5_bus3_manufact                          False\n",
       "5_bus3_product                           False\n",
       "5_X.dev.mapper.cloud..5.root_MBfsfree    False\n",
       "5_X.dev.mapper.cloud..5.root_MBfsused    False\n",
       "5_X.dev.mapper.cloud..5.root_.fsused     False\n",
       "5_X.dev.mapper.cloud..5.root_.ufsused    False\n",
       "5_X.dev.mapper.cloud..5.root_Ifree       False\n",
       "5_X.dev.mapper.cloud..5.root_Iused       False\n",
       "5_X.dev.mapper.cloud..5.root_.Iused      False\n",
       "5_X.dev.sda1_MBfsfree                    False\n",
       "5_X.dev.sda1_MBfsused                    False\n",
       "5_X.dev.sda1_.fsused                     False\n",
       "5_X.dev.sda1_.ufsused                    False\n",
       "5_X.dev.sda1_Ifree                       False\n",
       "5_X.dev.sda1_Iused                       False\n",
       "5_X.dev.sda1_.Iused                      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "data = pandas.read_csv('X_cluster.csv')\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20273\n",
      "8689\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "20273",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   2909\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2910\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_searchsorted_monotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2911\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_searchsorted_monotonic\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   2875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index must be monotonic increasing or decreasing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: index must be monotonic increasing or decreasing",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0da22fe233bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#print(training_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20273\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10374\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20273\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10376\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#print (len(train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m         elif (is_list_like_indexer(key) and\n\u001b[1;32m    994\u001b[0m               not (isinstance(key, tuple) and\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneed_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# if we are accessing via lowered dim, use the last dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_index_slice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   2783\u001b[0m         \"\"\"\n\u001b[1;32m   2784\u001b[0m         start_slice, end_slice = self.slice_locs(start, end, step=step,\n\u001b[0;32m-> 2785\u001b[0;31m                                                  kind=kind)\n\u001b[0m\u001b[1;32m   2786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m             \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m             \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2913\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   2905\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2907\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2908\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2909\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/surya/Anaconda/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:6610)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:6554)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 20273"
     ]
    }
   ],
   "source": [
    "#KV_periodic/X_cluster.csv -> working code copied from Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "A = genfromtxt('X_cluster.csv', delimiter = ',', dtype = 'float64')[1:]\n",
    "B = genfromtxt('Y1.csv' , delimiter = ',', dtype = 'float64')[1:]\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "#print(data_set)\n",
    "random.shuffle(data_set)\n",
    "\n",
    "data = pandas.DataFrame(data_set)\n",
    "df = data.fillna(0)\n",
    "training_set = df.sample(frac=0.7)\n",
    "train_size = len(training_set)\n",
    "test_set = df.loc[~df.index.isin(training_set.index)]\n",
    "test_size = len(test_set)\n",
    "print(len(training_set))\n",
    "print (len(test_set))\n",
    "\n",
    "#print(training_set)\n",
    "train = training_set.ix[:20273, :10374]\n",
    "target = training_set.ix[:20273, 10376]\n",
    "#print (len(train))\n",
    "#print (target)\n",
    "\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=120, n_jobs = 24)\n",
    "rf = rf.fit(train, target)\n",
    "end = time.time()\n",
    "print(\"hey hey\")\n",
    "print(end - start)\n",
    "print(\"this is the time!!\")\n",
    "y_pred = rf.predict(test_set.ix[:8690, :10374])\n",
    "print(y_pred)\n",
    "print(\"<<======================================================================================>>\")\n",
    "y_values = test_set.ix[:8690, 10376]\n",
    "print(y_values)\n",
    "MAE = mean_absolute_error(y_values, y_pred)\n",
    "print(MAE)\n",
    "m = mean(y_values) \n",
    "print(m)\n",
    "print(MAE/m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36633\n",
      "40\n",
      "Epoch 1/50\n",
      "25644/25644 [==============================] - 0s - loss: 444.1491 - acc: 4.6795e-04     \n",
      "Epoch 2/50\n",
      "25644/25644 [==============================] - 0s - loss: 291.4696 - acc: 0.0015     \n",
      "Epoch 3/50\n",
      "25644/25644 [==============================] - 0s - loss: 132.4797 - acc: 0.0175     \n",
      "Epoch 4/50\n",
      "25644/25644 [==============================] - 0s - loss: 50.1660 - acc: 0.0372     \n",
      "Epoch 5/50\n",
      "25644/25644 [==============================] - 0s - loss: 39.4666 - acc: 0.0483     \n",
      "Epoch 6/50\n",
      "25644/25644 [==============================] - 0s - loss: 33.5223 - acc: 0.0517     \n",
      "Epoch 7/50\n",
      "25644/25644 [==============================] - 0s - loss: 28.1461 - acc: 0.0578     \n",
      "Epoch 8/50\n",
      "25644/25644 [==============================] - 0s - loss: 23.6667 - acc: 0.0668     \n",
      "Epoch 9/50\n",
      "25644/25644 [==============================] - 0s - loss: 20.5302 - acc: 0.0737     \n",
      "Epoch 10/50\n",
      "25644/25644 [==============================] - 0s - loss: 18.4608 - acc: 0.0754     \n",
      "Epoch 11/50\n",
      "25644/25644 [==============================] - 0s - loss: 17.4778 - acc: 0.0673     \n",
      "Epoch 12/50\n",
      "25644/25644 [==============================] - 0s - loss: 17.0637 - acc: 0.0697     \n",
      "Epoch 13/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.9211 - acc: 0.0771     \n",
      "Epoch 14/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8662 - acc: 0.0799     \n",
      "Epoch 15/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8515 - acc: 0.0812     \n",
      "Epoch 16/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8504 - acc: 0.0840     \n",
      "Epoch 17/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8489 - acc: 0.0839     \n",
      "Epoch 18/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8477 - acc: 0.0850     \n",
      "Epoch 19/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8469 - acc: 0.0856     \n",
      "Epoch 20/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8492 - acc: 0.0852     \n",
      "Epoch 21/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8483 - acc: 0.0850     \n",
      "Epoch 22/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8481 - acc: 0.0855     \n",
      "Epoch 23/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8469 - acc: 0.0856     \n",
      "Epoch 24/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8440 - acc: 0.0854     \n",
      "Epoch 25/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8433 - acc: 0.0860     \n",
      "Epoch 26/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8487 - acc: 0.0859     \n",
      "Epoch 27/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8481 - acc: 0.0852     \n",
      "Epoch 28/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8472 - acc: 0.0863     \n",
      "Epoch 29/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8487 - acc: 0.0863     \n",
      "Epoch 30/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8440 - acc: 0.0866     \n",
      "Epoch 31/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8466 - acc: 0.0856     \n",
      "Epoch 32/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8446 - acc: 0.0873     \n",
      "Epoch 33/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8457 - acc: 0.0854     \n",
      "Epoch 34/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8438 - acc: 0.0861     \n",
      "Epoch 35/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8415 - acc: 0.0855     \n",
      "Epoch 36/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8454 - acc: 0.0851     \n",
      "Epoch 37/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8480 - acc: 0.0854     \n",
      "Epoch 38/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8404 - acc: 0.0864     \n",
      "Epoch 39/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8419 - acc: 0.0855     \n",
      "Epoch 40/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8432 - acc: 0.0865     \n",
      "Epoch 41/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8424 - acc: 0.0856     \n",
      "Epoch 42/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8384 - acc: 0.0870     \n",
      "Epoch 43/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8432 - acc: 0.0828     \n",
      "Epoch 44/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8418 - acc: 0.0857     \n",
      "Epoch 45/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8402 - acc: 0.0859     \n",
      "Epoch 46/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8447 - acc: 0.0857     \n",
      "Epoch 47/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8460 - acc: 0.0848     \n",
      "Epoch 48/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8384 - acc: 0.0856     \n",
      "Epoch 49/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8365 - acc: 0.0858     \n",
      "Epoch 50/50\n",
      "25644/25644 [==============================] - 0s - loss: 16.8465 - acc: 0.0866     \n",
      "25644/25644 [==============================] - 0s\n",
      "16.746799469\n",
      "====================================\n",
      "0.0897285938263\n",
      "[[ 20.73379135]\n",
      " [ 22.6150589 ]\n",
      " [ 23.5709343 ]\n",
      " ..., \n",
      " [ 25.96519089]\n",
      " [ 20.46753311]\n",
      " [ 22.32967377]]\n",
      "39.1355\n",
      "19.4707\n",
      "0.134972410137\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from numpy import genfromtxt, savetxt\n",
    "from numpy import mean, concatenate, random\n",
    "from numpy import max, min\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 25, init=\"uniform\", activation=\"relu\")) \t# hidden layer with non-linear output function\n",
    "model.add(Dense(1, activation=\"linear\")) \t\t\t\t# output layer with linear activation function. this is important as it can also be sigmoid or any other thing as well\n",
    "model.compile(loss=\"mse\", optimizer= \"rmsprop\", metrics=[\"accuracy\"])\n",
    "#model.compile(loss=\"mse\", optimizer= \"sgd\", metrics=[\"accuracy\"])\n",
    "#model.compile(loss=\"mse\", optimizer= \"adadelta\", metrics=[\"accuracy\"]) \t\t\t # 'rmsprop’,\t# sgd might be more basic than rmsprop\n",
    "#is it mse or mae ??\n",
    "A = genfromtxt('X_flow.csv', delimiter = ',', dtype = 'double')[1:]\n",
    "B = genfromtxt('Y.csv' , delimiter = ',', dtype = 'double')[1:]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "A = min_max_scaler.fit_transform(A)\n",
    "\n",
    "data_set = concatenate((A, B), axis = 1)\n",
    "print(len(data_set))\n",
    "print(len(data_set[0]))\n",
    "\n",
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#data_set = min_max_scaler.fit_transform(data[:,0:25])\n",
    "\n",
    "random.shuffle(data_set)\n",
    "training_set = data_set[:25644, 0:25]\n",
    "target_set =  data_set [:25644, 38]\n",
    "\n",
    "test_set = data_set [25644:36634, 0:25]\n",
    "y_set = data_set[25644:36634, 38]\n",
    "\n",
    "#random.shuffle(data_set)\n",
    "#test_set = data_set [:25644, 0:25]\n",
    "#y_set = data_set[:25644, 38]\n",
    "\n",
    "#random.shuffle(data_set)\n",
    "#valid_set = data_set[:25644, 0:25]\n",
    "#y_valid_set = data_set[:25644, 38]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(training_set, target_set, nb_epoch=50, batch_size=100) # data as matrix of x values, labels an array of y values (DisplFrame rate)\n",
    "\n",
    "loss, accuracy = model.evaluate(valid_set, y_valid_set, batch_size = 25644)\n",
    "\n",
    "print(loss)\n",
    "print(\"====================================\")\n",
    "print(accuracy)\n",
    "\n",
    "predictions = model.predict(test_set)\n",
    "\n",
    "print(predictions)\n",
    "print(max(predictions))\n",
    "print(min(predictions))\n",
    "mae = mean_absolute_error(y_set, predictions)\n",
    "nmae = mae / mean(y_set)\n",
    "print(nmae)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
